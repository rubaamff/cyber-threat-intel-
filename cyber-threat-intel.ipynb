{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q gdown imbalanced-learn transformers scikit-learn tensorflow\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import joblib\n",
        "\n",
        "# Create models directory\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "blockchain_path = \"models/blockchain.json\"\n",
        "\n",
        "if not os.path.exists(blockchain_path):\n",
        "    with open(blockchain_path, \"w\") as f:\n",
        "        json.dump([], f)\n",
        "\n",
        "# Download and load NSL-KDD dataset\n",
        "!wget -q https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt -O /content/KDDTrain+.txt\n",
        "\n",
        "nsl = pd.read_csv(\"/content/KDDTrain+.txt\", header=None)\n",
        "nsl.columns = [\n",
        "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land',\n",
        "    'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
        "    'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
        "    'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n",
        "    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
        "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
        "    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "    'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
        "    'label', 'difficulty'\n",
        "]\n",
        "\n",
        "nsl = nsl.sample(n=50000, random_state=42)\n",
        "nsl['label'] = nsl['label'].apply(lambda x: 0 if x == 'normal' else 1)\n",
        "nsl = nsl.select_dtypes(include=[np.number])\n",
        "\n",
        "# Download and load CICIDS2017 dataset\n",
        "!gdown --folder https://drive.google.com/drive/folders/1BD8tEZ7K6ZBbxhexn40MFIkYSthriu0V?usp=drive_link -O /content/cicids2017 --quiet\n",
        "\n",
        "cic_path = \"/content/cicids2017/MachineLearningCSV /Wednesday-workingHours.pcap_ISCX.csv\"\n",
        "cic = pd.read_csv(cic_path).sample(n=50000, random_state=42)\n",
        "cic.columns = cic.columns.str.strip()\n",
        "cic = cic.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "cic['label'] = (cic['Label'] != 'BENIGN').astype(int)\n",
        "cic = cic.select_dtypes(include=[np.number])\n",
        "\n",
        "# Feature mapping between datasets\n",
        "mapping = {\n",
        "    'src_bytes': 'Flow Bytes/s', 'dst_bytes': 'Flow Packets/s',\n",
        "    'wrong_fragment': 'Fwd Header Length', 'num_failed_logins': 'Fwd Packets/s',\n",
        "    'hot': 'Flow IAT Mean', 'logged_in': 'Flow IAT Max', 'count': 'Fwd IAT Total',\n",
        "    'srv_count': 'Subflow Fwd Bytes', 'same_srv_rate': 'Fwd IAT Std',\n",
        "    'dst_host_srv_count': 'Flow IAT Std', 'dst_host_same_srv_rate': 'Idle Std',\n",
        "    'dst_host_diff_srv_rate': 'Idle Max', 'dst_host_serror_rate': 'Fwd Header Length.1',\n",
        "    'dst_host_srv_serror_rate': 'Flow Duration', 'srv_rerror_rate': 'Init_Win_bytes_forward',\n",
        "    'srv_serror_rate': 'Bwd Packet Length Min', 'rerror_rate': 'Bwd Packet Length Max',\n",
        "    'num_compromised': 'Bwd Packet Length Mean'\n",
        "}\n",
        "\n",
        "# Select and rename features for both datasets\n",
        "nsl2 = nsl[list(mapping.keys()) + ['label']].copy()\n",
        "cic2 = cic[[mapping[k] for k in mapping if mapping[k] in cic.columns] + ['label']].copy()\n",
        "cic2.columns = list(mapping.keys())[:len(cic2.columns)-1] + ['label']\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([nsl2, cic2], ignore_index=True).dropna()\n",
        "\n",
        "print(\"Class distribution before merge:\")\n",
        "print(\"NSL-KDD:\", nsl['label'].value_counts(normalize=True))\n",
        "print(\"CICIDS:\", cic['label'].value_counts(normalize=True))\n",
        "print(\"After merge:\", df['label'].value_counts(normalize=True))\n",
        "\n",
        "# Feature selection\n",
        "X = df.drop(\"label\", axis=1)\n",
        "y = df[\"label\"]\n",
        "\n",
        "mi = mutual_info_classif(X, y)\n",
        "mi_scores = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
        "print(\"Feature rankings (mutual information):\")\n",
        "print(mi_scores)\n",
        "\n",
        "top_features = X.columns[mi > 0.01]\n",
        "X = X[top_features]\n",
        "\n",
        "# Train-test split and scaling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Utility functions\n",
        "def save_conf_matrix(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"{title} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"models/{title}_cm.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def save_class_report(y_true, y_pred, name):\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    with open(f\"models/{name}_report.json\", \"w\") as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "\n",
        "def log_predictions(model_name, y_pred, y_true):\n",
        "    with open(blockchain_path, \"r+\") as f:\n",
        "        chain = json.load(f)\n",
        "        for i, (pred, actual) in enumerate(zip(y_pred, y_true)):\n",
        "            entry = {\n",
        "                \"model\": model_name,\n",
        "                \"timestamp\": str(datetime.utcnow()),\n",
        "                \"index\": len(chain) + i,\n",
        "                \"prediction\": int(pred),\n",
        "                \"actual\": int(actual),\n",
        "                \"hash\": hash(f\"{model_name}{pred}{actual}{len(chain)+i}\")\n",
        "            }\n",
        "            chain.append(entry)\n",
        "        f.seek(0)\n",
        "        json.dump(chain, f, indent=2)\n",
        "\n",
        "# Supervised models\n",
        "models = {\n",
        "    \"NaiveBayes\": GaussianNB(),\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for name, model in models.items():\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}, Training Time: {elapsed:.2f}s\")\n",
        "\n",
        "    cv = cross_val_score(model, X, y, cv=StratifiedKFold(5), scoring=\"accuracy\")\n",
        "    print(f\"{name} 5-Fold CV Scores: {cv}\")\n",
        "    print(f\"{name} Mean CV Score: {cv.mean():.4f} (+/- {cv.std()*2:.4f})\")\n",
        "\n",
        "    joblib.dump(model, f\"models/{name}.joblib\")\n",
        "    save_conf_matrix(y_test, y_pred, name)\n",
        "    save_class_report(y_test, y_pred, name)\n",
        "    log_predictions(name, y_pred, y_test)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc(fpr,tpr):.2f})\")\n",
        "\n",
        "# Unsupervised models\n",
        "unsupervised = {\n",
        "    \"KMeans\": KMeans(n_clusters=2, n_init=10, random_state=42),\n",
        "    \"DBSCAN\": DBSCAN(eps=0.5, min_samples=5),\n",
        "    \"IsolationForest\": IsolationForest(random_state=42, contamination=0.1)\n",
        "}\n",
        "\n",
        "for name, model in unsupervised.items():\n",
        "    start = time.time()\n",
        "    if name == \"DBSCAN\":\n",
        "        pred = model.fit_predict(X_test)\n",
        "        # DBSCAN returns -1 for outliers, 0 for inliers\n",
        "        pred = np.where(pred == -1, 1, 0)\n",
        "    else:\n",
        "        pred = model.fit_predict(X_test)\n",
        "        pred = np.where(pred == -1, 1, 0) if name == \"IsolationForest\" else pred\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    acc = accuracy_score(y_test, pred)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}, Training Time: {elapsed:.2f}s\")\n",
        "\n",
        "    save_conf_matrix(y_test, pred, name)\n",
        "    save_class_report(y_test, pred, name)\n",
        "    log_predictions(name, pred, y_test)\n",
        "\n",
        "# LSTM Model\n",
        "X_lstm_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_lstm_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, input_shape=(1, X_train.shape[1])),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "history = lstm_model.fit(X_lstm_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
        "elapsed = time.time() - start\n",
        "\n",
        "lstm_pred = (lstm_model.predict(X_lstm_test) > 0.5).astype(int).flatten()\n",
        "print(f\"LSTM Accuracy: {accuracy_score(y_test, lstm_pred):.4f}, Training Time: {elapsed:.2f}s\")\n",
        "\n",
        "lstm_model.save(\"models/LSTM_model.h5\")\n",
        "save_conf_matrix(y_test, lstm_pred, \"LSTM\")\n",
        "save_class_report(y_test, lstm_pred, \"LSTM\")\n",
        "log_predictions(\"LSTM\", lstm_pred, y_test)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, lstm_model.predict(X_lstm_test).flatten())\n",
        "plt.plot(fpr, tpr, label=f\"LSTM (AUC={auc(fpr,tpr):.2f})\")\n",
        "\n",
        "# Ensemble model\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('nb', models[\"NaiveBayes\"]),\n",
        "        ('svm', models[\"SVM\"]),\n",
        "        ('rf', models[\"RandomForest\"])\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "ensemble.fit(X_train, y_train)\n",
        "y_pred_ens = ensemble.predict(X_test)\n",
        "print(f\"Ensemble Accuracy: {accuracy_score(y_test, y_pred_ens):.4f}\")\n",
        "\n",
        "joblib.dump(ensemble, \"models/Ensemble.joblib\")\n",
        "save_conf_matrix(y_test, y_pred_ens, \"Ensemble\")\n",
        "save_class_report(y_test, y_pred_ens, \"Ensemble\")\n",
        "log_predictions(\"Ensemble\", y_pred_ens, y_test)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, ensemble.predict_proba(X_test)[:, 1])\n",
        "plt.plot(fpr, tpr, label=f\"Ensemble (AUC={auc(fpr,tpr):.2f})\")\n",
        "\n",
        "# Final ROC curve plot\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curves Comparison\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"models/roc_curves.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# Load and display blockchain entries\n",
        "with open(\"models/blockchain.json\", \"r\") as f:\n",
        "    chain = json.load(f)\n",
        "\n",
        "block_df = pd.DataFrame(chain)\n",
        "print(\"Blockchain sample entries:\")\n",
        "print(block_df.tail(10))\n",
        "print(f\"\\nTotal entries in blockchain: {len(block_df)}\")\n",
        "\n",
        "# Save feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': top_features,\n",
        "    'importance': mi[mi > 0.01]\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "feature_importance.to_csv(\"models/feature_importance.csv\", index=False)\n",
        "print(\"\\nFeature importance saved to models/feature_importance.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmkSJQLVWyQF",
        "outputId": "9523312b-4564-4d1a-e4a6-a1f8480fc430"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1Ix0hhlX00pJ6UHjZ_PMlwCRDQdhO0ENq\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n",
            "Class distribution before merge:\n",
            "NSL-KDD: label\n",
            "0    0.53208\n",
            "1    0.46792\n",
            "Name: proportion, dtype: float64\n",
            "CICIDS: label\n",
            "0    0.638023\n",
            "1    0.361977\n",
            "Name: proportion, dtype: float64\n",
            "After merge: label\n",
            "0    0.585005\n",
            "1    0.414995\n",
            "Name: proportion, dtype: float64\n",
            "Feature rankings (mutual information):\n",
            "src_bytes                   0.453837\n",
            "dst_bytes                   0.407876\n",
            "logged_in                   0.346348\n",
            "dst_host_srv_serror_rate    0.335166\n",
            "dst_host_srv_count          0.332055\n",
            "same_srv_rate               0.318792\n",
            "dst_host_serror_rate        0.301290\n",
            "count                       0.297446\n",
            "dst_host_diff_srv_rate      0.275547\n",
            "srv_rerror_rate             0.264125\n",
            "rerror_rate                 0.247429\n",
            "num_compromised             0.238406\n",
            "srv_serror_rate             0.213928\n",
            "hot                         0.209100\n",
            "num_failed_logins           0.197498\n",
            "srv_count                   0.197362\n",
            "wrong_fragment              0.165852\n",
            "dst_host_same_srv_rate      0.164575\n",
            "dtype: float64\n",
            "NaiveBayes Accuracy: 0.6220, Training Time: 0.03s\n",
            "NaiveBayes 5-Fold CV Scores: [0.58479708 0.58484712 0.57701932 0.83309979 0.83284956]\n",
            "NaiveBayes Mean CV Score: 0.6825 (+/- 0.2458)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614860334.py:131: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": str(datetime.utcnow()),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.7389, Training Time: 2479.68s\n",
            "SVM 5-Fold CV Scores: [0.58519742 0.58504729 0.62596337 0.84375938 0.8441097 ]\n",
            "SVM Mean CV Score: 0.6968 (+/- 0.2421)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614860334.py:131: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": str(datetime.utcnow()),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest Accuracy: 0.9978, Training Time: 12.96s\n",
            "RandomForest 5-Fold CV Scores: [0.99744783 0.99704749 0.99769793 0.99769793 0.99669703]\n",
            "RandomForest Mean CV Score: 0.9973 (+/- 0.0008)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614860334.py:131: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": str(datetime.utcnow()),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Accuracy: 0.6796, Training Time: 0.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614860334.py:131: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": str(datetime.utcnow()),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DBSCAN Accuracy: 0.5707, Training Time: 11.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614860334.py:131: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": str(datetime.utcnow()),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IsolationForest Accuracy: 0.5869, Training Time: 0.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614860334.py:131: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": str(datetime.utcnow()),\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Accuracy: 0.8829, Training Time: 100.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614860334.py:131: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": str(datetime.utcnow()),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Ensemble Accuracy: 0.9867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614860334.py:131: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": str(datetime.utcnow()),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blockchain sample entries:\n",
            "           model                   timestamp   index  prediction  actual  \\\n",
            "159854  Ensemble  2025-08-27 18:32:11.974726  179827           1       1   \n",
            "159855  Ensemble  2025-08-27 18:32:11.974733  179829           0       0   \n",
            "159856  Ensemble  2025-08-27 18:32:11.974739  179831           1       1   \n",
            "159857  Ensemble  2025-08-27 18:32:11.974746  179833           1       1   \n",
            "159858  Ensemble  2025-08-27 18:32:11.974752  179835           1       1   \n",
            "159859  Ensemble  2025-08-27 18:32:11.974758  179837           1       1   \n",
            "159860  Ensemble  2025-08-27 18:32:11.974765  179839           0       0   \n",
            "159861  Ensemble  2025-08-27 18:32:11.974771  179841           0       0   \n",
            "159862  Ensemble  2025-08-27 18:32:11.974778  179843           1       1   \n",
            "159863  Ensemble  2025-08-27 18:32:11.974786  179845           0       0   \n",
            "\n",
            "                       hash  \n",
            "159854  3617636844703803078  \n",
            "159855 -3683492907553031627  \n",
            "159856  -308788786366558306  \n",
            "159857   -37346482625891254  \n",
            "159858  -337464655966937415  \n",
            "159859  6695154385325087432  \n",
            "159860  7080323311090473111  \n",
            "159861  5084828126505679053  \n",
            "159862 -7308383205908041035  \n",
            "159863 -5383629387690659019  \n",
            "\n",
            "Total entries in blockchain: 159864\n",
            "\n",
            "Feature importance saved to models/feature_importance.csv\n"
          ]
        }
      ]
    }
  ]
}